{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zarr_merge import merge_zarr_datasets\n",
    "from utils import print_func, permute_in_chunks\n",
    "import numpy as np\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 4\n",
      "Array Type: type_A | Num Features: 4 | Chunk Size: (5000, 4)\n",
      "Array Type: type_C | Num Features: 2 | Chunk Size: (5000, 2)\n",
      "Array Type: type_B | Num Features: 2 | Chunk Size: (5000, 2)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "CPU times: user 645 Âµs, sys: 10.4 ms, total: 11 ms\n",
      "Wall time: 11.4 ms\n",
      "Array Type: type_A\n",
      "feature4\tfeature3\tfeature2\tfeature1\t\n",
      "9               0               8               7               \n",
      "0               0               2               1               \n",
      "12              0               11              10              \n",
      "0               0               4               3               \n",
      "\n",
      "Array Type: type_C\n",
      "feature6\tfeature7\t\n",
      "0               0               \n",
      "10              11              \n",
      "0               0               \n",
      "12              13              \n",
      "\n",
      "Array Type: type_B\n",
      "feature4\tfeature5\t\n",
      "0               0               \n",
      "5               6               \n",
      "0               0               \n",
      "7               8               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset1 = {\n",
    "    \"type_A\": (zarr.array([[1, 2, 0], [3, 4, 0]]), [\"feature1\", \"feature2\", \"feature3\"]),\n",
    "    \"type_B\": (zarr.array([[5, 6], [7, 8]]), [\"feature4\", \"feature5\"])\n",
    "}\n",
    "dataset2 = {\n",
    "    \"type_A\": (zarr.array([[7, 8, 9], [10, 11, 12]]), [\"feature1\", \"feature2\", \"feature4\"]),\n",
    "    \"type_C\": (zarr.array([[10, 11], [12, 13]]), [\"feature6\", \"feature7\"])\n",
    "}\n",
    "qc = [dataset1, dataset2]\n",
    "%time setqc = merge_zarr_datasets(qc)\n",
    "print_func(setqc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test sets to verify the function\n",
    "dataset_a1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), store='feature/a1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 10)), store='feature/a1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "dataset_a2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), store='feature/a2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 10)), store='feature/a2-c.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "}\n",
    "dataset_a3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), store='feature/a3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_D\": (zarr.array(np.random.randint(0, 10, (10, 10)), store='feature/a3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "}\n",
    "\n",
    "test_set1 = [dataset_a1, dataset_a2, dataset_a3]\n",
    "\n",
    "# Larger test set using store and 100 rows and 100 columns\n",
    "dataset_b1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 100)), store='feature/b1-a.zarr'), [f\"feature{i}\" for i in range(100)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 100)), store='feature/b1-b.zarr'), [f\"feature{i}\" for i in range(100)])\n",
    "    }\n",
    "dataset_b2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 100)), store='feature/b2-a.zarr'), [f\"feature{i}\" for i in range(100)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 100)), store='feature/b2-c.zarr'), [f\"feature{i}\" for i in range(100)])\n",
    "}\n",
    "dataset_b3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 100)), store='feature/b3-a.zarr'), [f\"feature{i}\" for i in range(100)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 100)), store='feature/b3-b.zarr'), [f\"feature{i}\" for i in range(100)])\n",
    "}\n",
    "test_set2 = [dataset_b1, dataset_b2, dataset_b3]\n",
    "\n",
    "dataset_c1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 1000)), store='feature/c1-a.zarr'), [f\"feature{i}\" for i in range(1000)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 1000)), store='feature/c1-b.zarr'), [f\"feature{i}\" for i in range(1000)])\n",
    "    }\n",
    "dataset_c2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 1000)), store='feature/c2-a.zarr'), [f\"feature{i}\" for i in range(1000)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 1000)), store='feature/c2-c.zarr'), [f\"feature{i}\" for i in range(1000)])\n",
    "}\n",
    "dataset_c3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 1000)), store='feature/c3-a.zarr'), [f\"feature{i}\" for i in range(1000)]),\n",
    "    \"type_D\": (zarr.array(np.random.randint(0, 10, (10, 1000)), store='feature/c3-d.zarr'), [f\"feature{i}\" for i in range(1000)])\n",
    "}\n",
    "test_set3 = [dataset_c1, dataset_c2, dataset_c3]\n",
    "\n",
    "dataset_d1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10000)), store='feature/d1-a.zarr'), [f\"feature{i}\" for i in range(10000)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 10000)), store='feature/d1-b.zarr'), [f\"feature{i}\" for i in range(10000)])\n",
    "    }\n",
    "dataset_d2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10000)), store='feature/d2-a.zarr'), [f\"feature{i}\" for i in range(10000)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 10000)), store='feature/d2-c.zarr'), [f\"feature{i}\" for i in range(10000)])\n",
    "}\n",
    "dataset_d3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10000)), store='feature/d3-a.zarr'), [f\"feature{i}\" for i in range(10000)]),\n",
    "    \"type_D\": (zarr.array(np.random.randint(0, 10, (10, 10000)), store='feature/d3-d.zarr'), [f\"feature{i}\" for i in range(10000)])\n",
    "}\n",
    "test_set4 = [dataset_d1, dataset_d2, dataset_d3]\n",
    "\n",
    "dataset_e1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 100000)), store='feature/e1-a.zarr'), [f\"feature{i}\" for i in range(100000)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 100000)), store='feature/e1-b.zarr'), [f\"feature{i}\" for i in range(100000)])\n",
    "    }\n",
    "dataset_e2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 100000)), store='feature/e2-a.zarr'), [f\"feature{i}\" for i in range(100000)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 100000)), store='feature/e2-c.zarr'), [f\"feature{i}\" for i in range(100000)])\n",
    "}\n",
    "dataset_e3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 100000)), store='feature/e3-a.zarr'), [f\"feature{i}\" for i in range(100000)]),\n",
    "    \"type_D\": (zarr.array(np.random.randint(0, 10, (10, 100000)), store='feature/e3-d.zarr'), [f\"feature{i}\" for i in range(100000)])\n",
    "}\n",
    "test_set5 = [dataset_e1, dataset_e2, dataset_e3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 30\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "CPU times: user 43.4 ms, sys: 12.7 ms, total: 56.1 ms\n",
      "Wall time: 61.2 ms\n"
     ]
    }
   ],
   "source": [
    "%time set1 = merge_zarr_datasets(test_set1) # Max RAM 3.42 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 30\n",
      "Array Type: type_A | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Array Type: type_C | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Array Type: type_B | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "CPU times: user 375 ms, sys: 94.4 ms, total: 469 ms\n",
      "Wall time: 203 ms\n"
     ]
    }
   ],
   "source": [
    "%time set2 = merge_zarr_datasets(test_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 30\n",
      "Array Type: type_A | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Array Type: type_C | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Array Type: type_B | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Array Type: type_D | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "CPU times: user 1.21 s, sys: 171 ms, total: 1.38 s\n",
      "Wall time: 502 ms\n"
     ]
    }
   ],
   "source": [
    "%time set3 = merge_zarr_datasets(test_set3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 30\n",
      "Array Type: type_A | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Array Type: type_C | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Array Type: type_B | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Array Type: type_D | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "CPU times: user 1.48 s, sys: 252 ms, total: 1.73 s\n",
      "Wall time: 840 ms\n"
     ]
    }
   ],
   "source": [
    "%time set4 = merge_zarr_datasets(test_set4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 30\n",
      "Array Type: type_A | Num Features: 100000 | Chunk Size: (12, 100000)\n",
      "Array Type: type_C | Num Features: 100000 | Chunk Size: (12, 100000)\n",
      "Array Type: type_B | Num Features: 100000 | Chunk Size: (12, 100000)\n",
      "Array Type: type_D | Num Features: 100000 | Chunk Size: (12, 100000)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "CPU times: user 5.82 s, sys: 170 ms, total: 5.99 s\n",
      "Wall time: 5.2 s\n"
     ]
    }
   ],
   "source": [
    "%time set5 = merge_zarr_datasets(test_set5) # Max RAM 3.42 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Row Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautam-ahuja/miniconda3/envs/zarr/lib/python3.10/site-packages/zarr/creation.py:190: UserWarning: ignoring keyword argument 'chunk'\n",
      "  compressor, fill_value = _kwargs_compat(compressor, fill_value, kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Make test sets to verify the function\n",
    "dataset_a1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (2500, 10), store='row/a1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (2500, 10), store='row/a1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "dataset_a2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (2500, 10), store='row/a2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (2500, 10), store='row/a2-c.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "}\n",
    "dataset_a3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (2500, 10), store='row/a3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_D\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (2500, 10), store='row/a3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "}\n",
    "\n",
    "test_set1 = [dataset_a1, dataset_a2, dataset_a3]\n",
    "\n",
    "# Larger test set using store and 100 rows and 100 columns\n",
    "dataset_b1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (100, 10)), chunk = (2500, 10), store='row/b1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 100, (100, 10)), chunk = (2500, 10), store='row/b1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "dataset_b2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (100, 10)), chunk = (2500, 10), store='row/b2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 100, (100, 10)), chunk = (2500, 10), store='row/b2-c.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "}\n",
    "dataset_b3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (100, 10)), chunk = (2500, 10), store='row/b3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_D\": (zarr.array(np.random.randint(0, 100, (100, 10)), chunk = (2500, 10), store='row/b3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "}\n",
    "test_set2 = [dataset_b1, dataset_b2, dataset_b3]\n",
    "\n",
    "dataset_c1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (1000, 10)), chunk = (2500, 10), store='row/c1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 100, (1000, 10)), chunk = (2500, 10), store='row/c1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "dataset_c2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (1000, 10)), chunk = (2500, 10), store='row/c2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 100, (1000, 10)), chunk = (2500, 10), store='row/c2-c.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "}\n",
    "dataset_c3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (1000, 10)), chunk = (2500, 10), store='row/c3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_D\": (zarr.array(np.random.randint(0, 100, (1000, 10)), chunk = (2500, 10), store='row/c3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "}\n",
    "test_set3 = [dataset_c1, dataset_c2, dataset_c3]\n",
    "\n",
    "dataset_d1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (10000, 10)), chunk = (2500, 10), store='row/d1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 100, (10000, 10)), chunk = (2500, 10), store='row/d1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "dataset_d2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (10000, 10)), chunk = (2500, 10), store='row/d2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 100, (10000, 10)), chunk = (2500, 10), store='row/d2-c.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "}\n",
    "dataset_d3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (10000, 10)), chunk = (2500, 10), store='row/d3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_D\": (zarr.array(np.random.randint(0, 100, (10000, 10)), chunk = (2500, 10), store='row/d3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "}\n",
    "test_set4 = [dataset_d1, dataset_d2, dataset_d3]\n",
    "\n",
    "dataset_e1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (100000, 10)), chunk = (2500, 10), store='row/e1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 100, (100000, 10)), chunk = (2500, 10), store='row/e1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "dataset_e2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (100000, 10)), chunk = (2500, 10), store='row/e2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 100, (100000, 10)), chunk = (2500, 10), store='row/e2-c.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "}\n",
    "dataset_e3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (100000, 10)), chunk = (2500, 10), store='row/e3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_D\": (zarr.array(np.random.randint(0, 100, (100000, 10)), chunk = (2500, 10), store='row/e3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "}\n",
    "test_set5 = [dataset_e1, dataset_e2, dataset_e3]\n",
    "\n",
    "# dataset_f1 = {\n",
    "#     \"type_A\": (zarr.array(np.random.randint(0, 100, (1000000, 10)), chunk = (2500, 10), store='row/f1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "#     \"type_B\": (zarr.array(np.random.randint(0, 100, (1000000, 10)), chunk = (2500, 10), store='row/f1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "#     }\n",
    "# dataset_f2 = {\n",
    "#     \"type_A\": (zarr.array(np.random.randint(0, 100, (1000000, 10)), chunk = (2500, 10), store='row/f2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "#     \"type_C\": (zarr.array(np.random.randint(0, 100, (1000000, 10)), chunk = (2500, 10), store='row/f2-c.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "# }\n",
    "# dataset_f3 = {\n",
    "#     \"type_A\": (zarr.array(np.random.randint(0, 100, (1000000, 10)), chunk = (2500, 10), store='row/f3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "#     \"type_D\": (zarr.array(np.random.randint(0, 100, (1000000, 10)), chunk = (2500, 10), store='row/f3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "# }\n",
    "# test_set6 = [dataset_f1, dataset_f2, dataset_f3]\n",
    "\n",
    "# dataset_g1 = {\n",
    "#     \"type_A\": (zarr.array(np.random.randint(0, 100, (10000000, 10)), chunk = (2500, 10), store='row/g1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "#     \"type_B\": (zarr.array(np.random.randint(0, 100, (10000000, 10)), chunk = (2500, 10), store='row/g1-b.zarr'), [f\"feature{i}\" for i in range(10])]\n",
    "#     }\n",
    "# dataset_g2 = {\n",
    "#     \"type_A\": (zarr.array(np.random.randint(0, 100, (10000000, 10)), chunk = (2500, 10), store='row/g2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "#     \"type_C\": (zarr.array(np.random.randint(0, 100, (10000000, 10)), chunk = (2500, 10), store='row/g2-c.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "# }\n",
    "# dataset_g3 = {\n",
    "#     \"type_A\": (zarr.array(np.random.randint(0, 100, (10000000, 10)), chunk = (2500, 10), store='row/g3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "#     \"type_D\": (zarr.array(np.random.randint(0, 100, (10000000, 10)), chunk = (2500, 10), store='row/g3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "# }\n",
    "# test_set7 = [dataset_g1, dataset_g2, dataset_g3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 30\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "CPU times: user 42.8 ms, sys: 19.1 ms, total: 61.9 ms\n",
      "Wall time: 62 ms\n"
     ]
    }
   ],
   "source": [
    "%time set1 = merge_zarr_datasets(test_set1) # Max RAM 3.5 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 300\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "CPU times: user 295 ms, sys: 89.8 ms, total: 385 ms\n",
      "Wall time: 385 ms\n"
     ]
    }
   ],
   "source": [
    "%time set2 = merge_zarr_datasets(test_set2) # Max RAM 3.5 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 3000\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "CPU times: user 4.42 s, sys: 827 ms, total: 5.25 s\n",
      "Wall time: 5.3 s\n"
     ]
    }
   ],
   "source": [
    "%time set3 = merge_zarr_datasets(test_set3) # Max RAM 3.5 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 30000\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "CPU times: user 1min 2s, sys: 13.3 s, total: 1min 15s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%time set4 = merge_zarr_datasets(test_set4) # Max RAM 3.63 GB\n",
    "# 20-25 second per `array_type` merge containing 10,000 each of 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 300000\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "CPU times: user 18min 42s, sys: 2min 57s, total: 21min 39s\n",
      "Wall time: 21min 40s\n"
     ]
    }
   ],
   "source": [
    "%time set5 = merge_zarr_datasets(test_set5)\n",
    "# Base RAM 3.51 GB\n",
    "# After running RAM 3.56 GB\n",
    "# RAM used: 0.05 GB = 50 MB\n",
    "# 4-5 minute per `array_type` merge containing 100,000 each of 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time set6 = merge_zarr_datasets(test_set6) # Max RAM 3.84 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time set7 = merge_zarr_datasets(test_set7) # Max RAM 3.84 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_a1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (5000, 10), store='mix/a1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (5000, 10), store='mix/a1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "dataset_a2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (5000, 10), store='mix/a2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (5000, 10), store='mix/a2-c.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "}\n",
    "dataset_a3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (5000, 10), store='mix/a3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    \"type_D\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (5000, 10), store='mix/a3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "}\n",
    "\n",
    "test_set1 = [dataset_a1, dataset_a2, dataset_a3]\n",
    "\n",
    "dataset_b1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (100, 100)), chunk = (5000, 100), store='mix/b1-a.zarr'), [f\"feature{i}\" for i in range(100)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 100, (100, 100)), chunk = (5000, 100), store='mix/b1-b.zarr'), [f\"feature{i}\" for i in range(100)])\n",
    "}\n",
    "dataset_b2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (100, 100)), chunk = (5000, 100), store='mix/b2-a.zarr'), [f\"feature{i}\" for i in range(100)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 100, (100, 100)), chunk = (5000, 100), store='mix/b2-c.zarr'), [f\"feature{i}\" for i in range(100)]\n",
    "    )\n",
    "}\n",
    "dataset_b3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (100, 100)), chunk = (5000, 100), store='mix/b3-a.zarr'), [f\"feature{i}\" for i in range(100)]),\n",
    "    \"type_D\": (zarr.array(np.random.randint(0, 100, (100, 100)), chunk = (5000, 100), store='mix/b3-d.zarr'), [f\"feature{i}\" for i in range(100)]\n",
    "    )\n",
    "}\n",
    "test_set2 = [dataset_b1, dataset_b2, dataset_b3]\n",
    "\n",
    "dataset_c1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (1000, 1000)), chunk = (5000, 1000), store='mix/c1-a.zarr'), [f\"feature{i}\" for i in range(1000)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 100, (1000, 1000)), chunk = (5000, 1000), store='mix/c1-b.zarr'), [f\"feature{i}\" for i in range(1000)])\n",
    "}\n",
    "dataset_c2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (1000, 1000)), chunk = (5000, 1000), store='mix/c2-a.zarr'), [f\"feature{i}\" for i in range(1000)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 100, (1000, 1000)), chunk = (5000, 1000), store='mix/c2-c.zarr'), [f\"feature{i}\" for i in range(1000)]\n",
    "    )\n",
    "}\n",
    "dataset_c3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (1000, 1000)), chunk = (5000, 1000), store='mix/c3-a.zarr'), [f\"feature{i}\" for i in range(1000)]),\n",
    "    \"type_D\": (zarr.array(np.random.randint(0, 100, (1000, 1000)), chunk = (5000, 1000), store='mix/c3-d.zarr'), [f\"feature{i}\" for i in range(1000)]\n",
    "    )\n",
    "}\n",
    "test_set3 = [dataset_c1, dataset_c2, dataset_c3]\n",
    "\n",
    "dataset_d1 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (10000, 10000)), chunk = (5000, 10000), store='mix/d1-a.zarr'), [f\"feature{i}\" for i in range(10000)]),\n",
    "    \"type_B\": (zarr.array(np.random.randint(0, 100, (10000, 10000)), chunk = (5000, 10000), store='mix/d1-b.zarr'), [f\"feature{i}\" for i in range(10000)]\n",
    "    )\n",
    "}\n",
    "\n",
    "dataset_d2 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (10000, 10000)), chunk = (5000, 10000), store='mix/d2-a.zarr'), [f\"feature{i}\" for i in range(10000)]),\n",
    "    \"type_C\": (zarr.array(np.random.randint(0, 100, (10000, 10000)), chunk = (5000, 10000), store='mix/d2-c.zarr'), [f\"feature{i}\" for i in range(10000)]\n",
    "    )\n",
    "}\n",
    "dataset_d3 = {\n",
    "    \"type_A\": (zarr.array(np.random.randint(0, 100, (10000, 10000)), chunk = (5000, 10000), store='mix/d3-a.zarr'), [f\"feature{i}\" for i in range(10000)]),\n",
    "    \"type_D\": (zarr.array(np.random.randint(0, 100, (10000, 10000)), chunk = (5000, 10000), store='mix/d3-d.zarr'), [f\"feature{i}\" for i in range(10000)]\n",
    "    )\n",
    "}\n",
    "test_set4 = [dataset_d1, dataset_d2, dataset_d3]\n",
    "\n",
    "# dataset_e1 = {\n",
    "#     \"type_A\": (zarr.array(np.random.randint(0, 100, (100000, 100000)), chunk = (5000, 100000), store='mix/e1-a.zarr'), [f\"feature{i}\" for i in range(100000)]),\n",
    "#     \"type_B\": (zarr.array(np.random.randint(0, 100, (100000, 100000)), chunk = (5000, 100000), store='mix/e1-b.zarr'), [f\"feature{i}\" for i in range(100000)]\n",
    "#     )\n",
    "# }\n",
    "# dataset_e2 = {\n",
    "#     \"type_A\": (zarr.array(np.random.randint(0, 100, (100000, 100000)), chunk = (5000, 100000), store='mix/e2-a.zarr'), [f\"feature{i}\" for i in range(100000)]),\n",
    "#     \"type_C\": (zarr.array(np.random.randint(0, 100, (100000, 100000)), chunk = (5000, 100000), store='mix/e2-c.zarr'), [f\"feature{i}\" for i in range(100000)]\n",
    "#     )\n",
    "# }\n",
    "# dataset_e3 = {\n",
    "#     \"type_A\": (zarr.array(np.random.randint(0, 100, (100000, 100000)), chunk = (5000, 100000), store='mix/e3-a.zarr'), [f\"feature{i}\" for i in range(100000)]),\n",
    "#     \"type_D\": (zarr.array(np.random.randint(0, 100, (100000, 100000)), chunk = (5000, 100000), store='mix/e3-d.zarr'), [f\"feature{i}\" for i in range(100000)]\n",
    "#     )\n",
    "# }\n",
    "# test_set5 = [dataset_e1, dataset_e2, dataset_e3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 30\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "CPU times: user 62 ms, sys: 1.94 ms, total: 64 ms\n",
      "Wall time: 78.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time set1 = merge_zarr_datasets(test_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 300\n",
      "Array Type: type_A | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Array Type: type_C | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Array Type: type_B | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Array Type: type_D | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\t\tRow: 14/100\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "CPU times: user 4.89 s, sys: 1.11 s, total: 6 s\n",
      "Wall time: 2.97 s\n"
     ]
    }
   ],
   "source": [
    "%time set2 = merge_zarr_datasets(test_set2) # Max RAM 3.5 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 3000\n",
      "Array Type: type_A | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Array Type: type_C | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Array Type: type_B | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Array Type: type_D | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "CPU times: user 2min 8s, sys: 18.5 s, total: 2min 27s\n",
      "Wall time: 57.7 s\n"
     ]
    }
   ],
   "source": [
    "%time set3 = merge_zarr_datasets(test_set3) # Max RAM 3.5 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_A | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Array Type: type_C | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Array Type: type_B | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Array Type: type_D | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_D\n",
      "CPU times: user 31min 51s, sys: 3min 10s, total: 35min 2s\n",
      "Wall time: 20min 12s\n"
     ]
    }
   ],
   "source": [
    "%time set4 = merge_zarr_datasets(test_set4) # Max RAM 3.5 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zarr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
