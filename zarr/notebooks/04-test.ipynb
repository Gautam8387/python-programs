{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zarr_merge import merge_zarr_datasets\n",
    "from utils import print_func, permute_in_chunks\n",
    "import numpy as np\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_C | Num Features: 2 | Chunk Size: (2500, 2)\n",
      "Array Type: type_A | Num Features: 4 | Chunk Size: (2500, 4)\n",
      "Array Type: type_B | Num Features: 2 | Chunk Size: (2500, 2)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_C\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "CPU times: user 9.61 ms, sys: 9.43 ms, total: 19 ms\n",
      "Wall time: 17.3 ms\n",
      "Array Type: type_C\n",
      "feature7\tfeature6\t\n",
      "0               0               \n",
      "11              10              \n",
      "0               0               \n",
      "13              12              \n",
      "\n",
      "Array Type: type_A\n",
      "feature1\tfeature3\tfeature2\tfeature4\t\n",
      "7               0               8               9               \n",
      "1               0               2               0               \n",
      "10              0               11              12              \n",
      "3               0               4               0               \n",
      "\n",
      "Array Type: type_B\n",
      "feature5\tfeature4\t\n",
      "0               0               \n",
      "6               5               \n",
      "0               0               \n",
      "8               7               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset1 = {\n",
    "    \"type_A\": (zarr.array([[1, 2, 0], [3, 4, 0]]), [\"feature1\", \"feature2\", \"feature3\"]),\n",
    "    \"type_B\": (zarr.array([[5, 6], [7, 8]]), [\"feature4\", \"feature5\"])\n",
    "}\n",
    "dataset2 = {\n",
    "    \"type_A\": (zarr.array([[7, 8, 9], [10, 11, 12]]), [\"feature1\", \"feature2\", \"feature4\"]),\n",
    "    \"type_C\": (zarr.array([[10, 11], [12, 13]]), [\"feature6\", \"feature7\"])\n",
    "}\n",
    "qc = [dataset1, dataset2]\n",
    "%time setqc = merge_zarr_datasets(qc)\n",
    "print_func(setqc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_test():\n",
    "    # Make test sets to verify the function\n",
    "    dataset_a1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), store='feature/a1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 10)), store='feature/a1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "        }\n",
    "    dataset_a2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), store='feature/a2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 10)), store='feature/a2-c.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "    dataset_a3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), store='feature/a3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_D\": (zarr.array(np.random.randint(0, 10, (10, 10)), store='feature/a3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "\n",
    "    test_set1 = [dataset_a1, dataset_a2, dataset_a3]\n",
    "\n",
    "    # Larger test set using store and 100 rows and 100 columns\n",
    "    dataset_b1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 100)), store='feature/b1-a.zarr'), [f\"feature{i}\" for i in range(100)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 100)), store='feature/b1-b.zarr'), [f\"feature{i}\" for i in range(100)])\n",
    "        }\n",
    "    dataset_b2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 100)), store='feature/b2-a.zarr'), [f\"feature{i}\" for i in range(100)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 100)), store='feature/b2-c.zarr'), [f\"feature{i}\" for i in range(100)])\n",
    "    }\n",
    "    dataset_b3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 100)), store='feature/b3-a.zarr'), [f\"feature{i}\" for i in range(100)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 100)), store='feature/b3-b.zarr'), [f\"feature{i}\" for i in range(100)])\n",
    "    }\n",
    "    test_set2 = [dataset_b1, dataset_b2, dataset_b3]\n",
    "\n",
    "    dataset_c1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 1000)), store='feature/c1-a.zarr'), [f\"feature{i}\" for i in range(1000)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 1000)), store='feature/c1-b.zarr'), [f\"feature{i}\" for i in range(1000)])\n",
    "        }\n",
    "    dataset_c2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 1000)), store='feature/c2-a.zarr'), [f\"feature{i}\" for i in range(1000)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 1000)), store='feature/c2-c.zarr'), [f\"feature{i}\" for i in range(1000)])\n",
    "    }\n",
    "    dataset_c3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 1000)), store='feature/c3-a.zarr'), [f\"feature{i}\" for i in range(1000)]),\n",
    "        \"type_D\": (zarr.array(np.random.randint(0, 10, (10, 1000)), store='feature/c3-d.zarr'), [f\"feature{i}\" for i in range(1000)])\n",
    "    }\n",
    "    test_set3 = [dataset_c1, dataset_c2, dataset_c3]\n",
    "\n",
    "    dataset_d1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10000)), store='feature/d1-a.zarr'), [f\"feature{i}\" for i in range(10000)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 10000)), store='feature/d1-b.zarr'), [f\"feature{i}\" for i in range(10000)])\n",
    "        }\n",
    "    dataset_d2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10000)), store='feature/d2-a.zarr'), [f\"feature{i}\" for i in range(10000)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 10000)), store='feature/d2-c.zarr'), [f\"feature{i}\" for i in range(10000)])\n",
    "    }\n",
    "    dataset_d3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10000)), store='feature/d3-a.zarr'), [f\"feature{i}\" for i in range(10000)]),\n",
    "        \"type_D\": (zarr.array(np.random.randint(0, 10, (10, 10000)), store='feature/d3-d.zarr'), [f\"feature{i}\" for i in range(10000)])\n",
    "    }\n",
    "    test_set4 = [dataset_d1, dataset_d2, dataset_d3]\n",
    "\n",
    "    dataset_e1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 100000)), store='feature/e1-a.zarr'), [f\"feature{i}\" for i in range(100000)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 100000)), store='feature/e1-b.zarr'), [f\"feature{i}\" for i in range(100000)])\n",
    "        }\n",
    "    dataset_e2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 100000)), store='feature/e2-a.zarr'), [f\"feature{i}\" for i in range(100000)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 100000)), store='feature/e2-c.zarr'), [f\"feature{i}\" for i in range(100000)])\n",
    "    }\n",
    "    dataset_e3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 100000)), store='feature/e3-a.zarr'), [f\"feature{i}\" for i in range(100000)]),\n",
    "        \"type_D\": (zarr.array(np.random.randint(0, 10, (10, 100000)), store='feature/e3-d.zarr'), [f\"feature{i}\" for i in range(100000)])\n",
    "    }\n",
    "    test_set5 = [dataset_e1, dataset_e2, dataset_e3]\n",
    "\n",
    "    return test_set1, test_set2, test_set3, test_set4, test_set5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 12.3 ms, sys: 11.4 ms, total: 23.7 ms\n",
      "Wall time: 32.3 ms\n"
     ]
    }
   ],
   "source": [
    "%time set1 = merge_zarr_datasets(test_set1) # Max RAM 3.42 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_A | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Array Type: type_B | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Array Type: type_C | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 39.8 ms, sys: 23.7 ms, total: 63.5 ms\n",
      "Wall time: 42.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time set2 = merge_zarr_datasets(test_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_D | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Array Type: type_A | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Array Type: type_B | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Array Type: type_C | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 118 ms, sys: 26.5 ms, total: 144 ms\n",
      "Wall time: 85.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time set3 = merge_zarr_datasets(test_set3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_D | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Array Type: type_A | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Array Type: type_B | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Array Type: type_C | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 370 ms, sys: 60.3 ms, total: 430 ms\n",
      "Wall time: 343 ms\n"
     ]
    }
   ],
   "source": [
    "%time set4 = merge_zarr_datasets(test_set4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_D | Num Features: 100000 | Chunk Size: (12, 100000)\n",
      "Array Type: type_A | Num Features: 100000 | Chunk Size: (12, 100000)\n",
      "Array Type: type_B | Num Features: 100000 | Chunk Size: (12, 100000)\n",
      "Array Type: type_C | Num Features: 100000 | Chunk Size: (12, 100000)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 4.67 s, sys: 163 ms, total: 4.84 s\n",
      "Wall time: 4.76 s\n"
     ]
    }
   ],
   "source": [
    "%time set5 = merge_zarr_datasets(test_set5) # Max RAM 3.42 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Row Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_test():\n",
    "    # Make test sets to verify the function\n",
    "    dataset_a1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (2500, 10), store='row/a1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (2500, 10), store='row/a1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "        }\n",
    "    dataset_a2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (2500, 10), store='row/a2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (2500, 10), store='row/a2-c.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    }\n",
    "    dataset_a3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (2500, 10), store='row/a3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_D\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (2500, 10), store='row/a3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "\n",
    "    test_set1 = [dataset_a1, dataset_a2, dataset_a3]\n",
    "\n",
    "    # Larger test set using store and 100 rows and 100 columns\n",
    "    dataset_b1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (100, 10)), chunk = (2500, 10), store='row/b1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 100, (100, 10)), chunk = (2500, 10), store='row/b1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "        }\n",
    "    dataset_b2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (100, 10)), chunk = (2500, 10), store='row/b2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 100, (100, 10)), chunk = (2500, 10), store='row/b2-c.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "    dataset_b3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (100, 10)), chunk = (2500, 10), store='row/b3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_D\": (zarr.array(np.random.randint(0, 100, (100, 10)), chunk = (2500, 10), store='row/b3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "    test_set2 = [dataset_b1, dataset_b2, dataset_b3]\n",
    "\n",
    "    dataset_c1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (1000, 10)), chunk = (2500, 10), store='row/c1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 100, (1000, 10)), chunk = (2500, 10), store='row/c1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "        }\n",
    "    dataset_c2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (1000, 10)), chunk = (2500, 10), store='row/c2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 100, (1000, 10)), chunk = (2500, 10), store='row/c2-c.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "    dataset_c3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (1000, 10)), chunk = (2500, 10), store='row/c3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_D\": (zarr.array(np.random.randint(0, 100, (1000, 10)), chunk = (2500, 10), store='row/c3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "    test_set3 = [dataset_c1, dataset_c2, dataset_c3]\n",
    "\n",
    "    dataset_d1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (10000, 10)), chunk = (2500, 10), store='row/d1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 100, (10000, 10)), chunk = (2500, 10), store='row/d1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "        }\n",
    "    dataset_d2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (10000, 10)), chunk = (2500, 10), store='row/d2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 100, (10000, 10)), chunk = (2500, 10), store='row/d2-c.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "    dataset_d3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (10000, 10)), chunk = (2500, 10), store='row/d3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_D\": (zarr.array(np.random.randint(0, 100, (10000, 10)), chunk = (2500, 10), store='row/d3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "    test_set4 = [dataset_d1, dataset_d2, dataset_d3]\n",
    "\n",
    "    dataset_e1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (100000, 10)), chunk = (2500, 10), store='row/e1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 100, (100000, 10)), chunk = (2500, 10), store='row/e1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "        }\n",
    "    dataset_e2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (100000, 10)), chunk = (2500, 10), store='row/e2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 100, (100000, 10)), chunk = (2500, 10), store='row/e2-c.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "    dataset_e3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (100000, 10)), chunk = (2500, 10), store='row/e3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_D\": (zarr.array(np.random.randint(0, 100, (100000, 10)), chunk = (2500, 10), store='row/e3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "    test_set5 = [dataset_e1, dataset_e2, dataset_e3]\n",
    "\n",
    "    # dataset_f1 = {\n",
    "    #     \"type_A\": (zarr.array(np.random.randint(0, 100, (1000000, 10)), chunk = (2500, 10), store='row/f1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    #     \"type_B\": (zarr.array(np.random.randint(0, 100, (1000000, 10)), chunk = (2500, 10), store='row/f1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    #     }\n",
    "    # dataset_f2 = {\n",
    "    #     \"type_A\": (zarr.array(np.random.randint(0, 100, (1000000, 10)), chunk = (2500, 10), store='row/f2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    #     \"type_C\": (zarr.array(np.random.randint(0, 100, (1000000, 10)), chunk = (2500, 10), store='row/f2-c.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    # }\n",
    "    # dataset_f3 = {\n",
    "    #     \"type_A\": (zarr.array(np.random.randint(0, 100, (1000000, 10)), chunk = (2500, 10), store='row/f3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    #     \"type_D\": (zarr.array(np.random.randint(0, 100, (1000000, 10)), chunk = (2500, 10), store='row/f3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    # }\n",
    "    # test_set6 = [dataset_f1, dataset_f2, dataset_f3]\n",
    "\n",
    "    # dataset_g1 = {\n",
    "    #     \"type_A\": (zarr.array(np.random.randint(0, 100, (10000000, 10)), chunk = (2500, 10), store='row/g1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    #     \"type_B\": (zarr.array(np.random.randint(0, 100, (10000000, 10)), chunk = (2500, 10), store='row/g1-b.zarr'), [f\"feature{i}\" for i in range(10])]\n",
    "    #     }\n",
    "    # dataset_g2 = {\n",
    "    #     \"type_A\": (zarr.array(np.random.randint(0, 100, (10000000, 10)), chunk = (2500, 10), store='row/g2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    #     \"type_C\": (zarr.array(np.random.randint(0, 100, (10000000, 10)), chunk = (2500, 10), store='row/g2-c.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    # }\n",
    "    # dataset_g3 = {\n",
    "    #     \"type_A\": (zarr.array(np.random.randint(0, 100, (10000000, 10)), chunk = (2500, 10), store='row/g3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    #     \"type_D\": (zarr.array(np.random.randint(0, 100, (10000000, 10)), chunk = (2500, 10), store='row/g3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    # }\n",
    "    # test_set7 = [dataset_g1, dataset_g2, dataset_g3]\n",
    "    return test_set1, test_set2, test_set3, test_set4, test_set5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 17 ms, sys: 9.51 ms, total: 26.5 ms\n",
      "Wall time: 27.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time set1 = merge_zarr_datasets(test_set1) # Max RAM 3.5 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 154 ms, sys: 49.1 ms, total: 203 ms\n",
      "Wall time: 204 ms\n"
     ]
    }
   ],
   "source": [
    "%time set2 = merge_zarr_datasets(test_set2) # Max RAM 3.5 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 664 ms, sys: 50.6 ms, total: 715 ms\n",
      "Wall time: 714 ms\n"
     ]
    }
   ],
   "source": [
    "%time set3 = merge_zarr_datasets(test_set3) # Max RAM 3.5 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 13.1 s, sys: 739 ms, total: 13.8 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%time set4 = merge_zarr_datasets(test_set4) # Max RAM 3.63 GB\n",
    "# 20-25 second per `array_type` merge containing 10,000 each of 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 9min 15s, sys: 31.4 s, total: 9min 46s\n",
      "Wall time: 9min 46s\n"
     ]
    }
   ],
   "source": [
    "%time set5 = merge_zarr_datasets(test_set5)\n",
    "# Base RAM 3.51 GB\n",
    "# After running RAM 3.56 GB\n",
    "# RAM used: 0.05 GB = 50 MB\n",
    "# 4-5 minute per `array_type` merge containing 100,000 each of 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time set6 = merge_zarr_datasets(test_set6) # Max RAM 3.84 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time set7 = merge_zarr_datasets(test_set7) # Max RAM 3.84 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_test():\n",
    "    dataset_a1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (5000, 10), store='mix/a1-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (5000, 10), store='mix/a1-b.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "        }\n",
    "    dataset_a2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (5000, 10), store='mix/a2-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (5000, 10), store='mix/a2-c.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "    }\n",
    "    dataset_a3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (5000, 10), store='mix/a3-a.zarr'), [f\"feature{i}\" for i in range(10)]),\n",
    "        \"type_D\": (zarr.array(np.random.randint(0, 10, (10, 10)), chunk = (5000, 10), store='mix/a3-d.zarr'), [f\"feature{i}\" for i in range(10)])\n",
    "    }\n",
    "\n",
    "    test_set1 = [dataset_a1, dataset_a2, dataset_a3]\n",
    "\n",
    "    dataset_b1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (100, 100)), chunk = (5000, 100), store='mix/b1-a.zarr'), [f\"feature{i}\" for i in range(100)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 100, (100, 100)), chunk = (5000, 100), store='mix/b1-b.zarr'), [f\"feature{i}\" for i in range(100)])\n",
    "    }\n",
    "    dataset_b2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (100, 100)), chunk = (5000, 100), store='mix/b2-a.zarr'), [f\"feature{i}\" for i in range(100)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 100, (100, 100)), chunk = (5000, 100), store='mix/b2-c.zarr'), [f\"feature{i}\" for i in range(100)]\n",
    "        )\n",
    "    }\n",
    "    dataset_b3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (100, 100)), chunk = (5000, 100), store='mix/b3-a.zarr'), [f\"feature{i}\" for i in range(100)]),\n",
    "        \"type_D\": (zarr.array(np.random.randint(0, 100, (100, 100)), chunk = (5000, 100), store='mix/b3-d.zarr'), [f\"feature{i}\" for i in range(100)]\n",
    "        )\n",
    "    }\n",
    "    test_set2 = [dataset_b1, dataset_b2, dataset_b3]\n",
    "\n",
    "    dataset_c1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (1000, 1000)), chunk = (5000, 1000), store='mix/c1-a.zarr'), [f\"feature{i}\" for i in range(1000)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 100, (1000, 1000)), chunk = (5000, 1000), store='mix/c1-b.zarr'), [f\"feature{i}\" for i in range(1000)])\n",
    "    }\n",
    "    dataset_c2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (1000, 1000)), chunk = (5000, 1000), store='mix/c2-a.zarr'), [f\"feature{i}\" for i in range(1000)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 100, (1000, 1000)), chunk = (5000, 1000), store='mix/c2-c.zarr'), [f\"feature{i}\" for i in range(1000)]\n",
    "        )\n",
    "    }\n",
    "    dataset_c3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (1000, 1000)), chunk = (5000, 1000), store='mix/c3-a.zarr'), [f\"feature{i}\" for i in range(1000)]),\n",
    "        \"type_D\": (zarr.array(np.random.randint(0, 100, (1000, 1000)), chunk = (5000, 1000), store='mix/c3-d.zarr'), [f\"feature{i}\" for i in range(1000)]\n",
    "        )\n",
    "    }\n",
    "    test_set3 = [dataset_c1, dataset_c2, dataset_c3]\n",
    "\n",
    "    dataset_d1 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (10000, 10000)), chunk = (5000, 10000), store='mix/d1-a.zarr'), [f\"feature{i}\" for i in range(10000)]),\n",
    "        \"type_B\": (zarr.array(np.random.randint(0, 100, (10000, 10000)), chunk = (5000, 10000), store='mix/d1-b.zarr'), [f\"feature{i}\" for i in range(10000)]\n",
    "        )\n",
    "    }\n",
    "\n",
    "    dataset_d2 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (10000, 10000)), chunk = (5000, 10000), store='mix/d2-a.zarr'), [f\"feature{i}\" for i in range(10000)]),\n",
    "        \"type_C\": (zarr.array(np.random.randint(0, 100, (10000, 10000)), chunk = (5000, 10000), store='mix/d2-c.zarr'), [f\"feature{i}\" for i in range(10000)]\n",
    "        )\n",
    "    }\n",
    "    dataset_d3 = {\n",
    "        \"type_A\": (zarr.array(np.random.randint(0, 100, (10000, 10000)), chunk = (5000, 10000), store='mix/d3-a.zarr'), [f\"feature{i}\" for i in range(10000)]),\n",
    "        \"type_D\": (zarr.array(np.random.randint(0, 100, (10000, 10000)), chunk = (5000, 10000), store='mix/d3-d.zarr'), [f\"feature{i}\" for i in range(10000)]\n",
    "        )\n",
    "    }\n",
    "    test_set4 = [dataset_d1, dataset_d2, dataset_d3]\n",
    "\n",
    "    # dataset_e1 = {\n",
    "    #     \"type_A\": (zarr.array(np.random.randint(0, 100, (100000, 100000)), chunk = (5000, 100000), store='mix/e1-a.zarr'), [f\"feature{i}\" for i in range(100000)]),\n",
    "    #     \"type_B\": (zarr.array(np.random.randint(0, 100, (100000, 100000)), chunk = (5000, 100000), store='mix/e1-b.zarr'), [f\"feature{i}\" for i in range(100000)]\n",
    "    #     )\n",
    "    # }\n",
    "    # dataset_e2 = {\n",
    "    #     \"type_A\": (zarr.array(np.random.randint(0, 100, (100000, 100000)), chunk = (5000, 100000), store='mix/e2-a.zarr'), [f\"feature{i}\" for i in range(100000)]),\n",
    "    #     \"type_C\": (zarr.array(np.random.randint(0, 100, (100000, 100000)), chunk = (5000, 100000), store='mix/e2-c.zarr'), [f\"feature{i}\" for i in range(100000)]\n",
    "    #     )\n",
    "    # }\n",
    "    # dataset_e3 = {\n",
    "    #     \"type_A\": (zarr.array(np.random.randint(0, 100, (100000, 100000)), chunk = (5000, 100000), store='mix/e3-a.zarr'), [f\"feature{i}\" for i in range(100000)]),\n",
    "    #     \"type_D\": (zarr.array(np.random.randint(0, 100, (100000, 100000)), chunk = (5000, 100000), store='mix/e3-d.zarr'), [f\"feature{i}\" for i in range(100000)]\n",
    "    #     )\n",
    "    # }\n",
    "    # test_set5 = [dataset_e1, dataset_e2, dataset_e3]\n",
    "    return test_set1, test_set2, test_set3, test_set4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautam-ahuja/miniconda3/envs/zarr/lib/python3.10/site-packages/zarr/creation.py:190: UserWarning: ignoring keyword argument 'chunk'\n",
      "  compressor, fill_value = _kwargs_compat(compressor, fill_value, kwargs)\n"
     ]
    }
   ],
   "source": [
    "test_set1, test_set2, test_set3, test_set4 = mix_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_D | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_A | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_B | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Array Type: type_C | Num Features: 10 | Chunk Size: (5000, 10)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 9.67 ms, sys: 9.98 ms, total: 19.7 ms\n",
      "Wall time: 22.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time set1 = merge_zarr_datasets(test_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_D | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Array Type: type_A | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Array Type: type_B | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Array Type: type_C | Num Features: 100 | Chunk Size: (5000, 100)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 164 ms, sys: 7.6 ms, total: 171 ms\n",
      "Wall time: 153 ms\n"
     ]
    }
   ],
   "source": [
    "%time set2 = merge_zarr_datasets(test_set2) # Max RAM 3.5 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_D | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Array Type: type_A | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Array Type: type_B | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Array Type: type_C | Num Features: 1000 | Chunk Size: (1250, 1000)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 5.96 s, sys: 392 ms, total: 6.35 s\n",
      "Wall time: 6.26 s\n"
     ]
    }
   ],
   "source": [
    "%time set3 = merge_zarr_datasets(test_set3) # Max RAM 3.5 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: type_D | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Array Type: type_A | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Array Type: type_B | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Array Type: type_C | Num Features: 10000 | Chunk Size: (125, 10000)\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "Starting new dataset\n",
      "\tRunning for array type: type_D\n",
      "\tRunning for array type: type_A\n",
      "\tRunning for array type: type_B\n",
      "\tRunning for array type: type_C\n",
      "CPU times: user 8min 56s, sys: 33.8 s, total: 9min 30s\n",
      "Wall time: 9min 24s\n"
     ]
    }
   ],
   "source": [
    "%time set4 = merge_zarr_datasets(test_set4) # Max RAM 3.5 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zarr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
